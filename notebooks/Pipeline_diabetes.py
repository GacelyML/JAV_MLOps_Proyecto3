# -*- coding: utf-8 -*-
"""Pipeline Diabetes dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1C7kImZJT8m5Eg3CKMgm_Eafl2YBaNUYH
"""

import pandas as pd
import os
import requests
import numpy as np
import re

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.base import BaseEstimator, TransformerMixin

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder

from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score, recall_score

## download the dataset
# Directory of the raw data files
_data_root = './data/Diabetes'
# Path to the raw training data
_data_filepath = os.path.join(_data_root, 'Diabetes.csv')
# Download data
os.makedirs(_data_root, exist_ok=True)
if not os.path.isfile(_data_filepath):
  #https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/
  url = 'https://docs.google.com/uc?export= \
  download&confirm={{VALUE}}&id=1k5-1caezQ3zWJbKaiMULTGq-3sz6uThC'
  r = requests.get(url, allow_redirects=True, stream=True)
  open(_data_filepath, 'wb').write(r.content)

df = pd.read_csv("data/Diabetes/Diabetes.csv", encoding="utf8")

df = df.replace("?",np.nan)

df.columns

df.drop(['weight','payer_code','medical_specialty','diag_1', 'diag_2', 'diag_3', 'metformin','repaglinide', 'nateglinide', 'chlorpropamide', 'glimepiride','acetohexamide', 'glipizide',
                'glyburide', 'tolbutamide','pioglitazone', 'rosiglitazone', 'acarbose', 'miglitol', 'troglitazone',
                'tolazamide', 'glyburide-metformin', 'glipizide-metformin','glimepiride-pioglitazone',
                'metformin-rosiglitazone','metformin-pioglitazone', 'insulin'],axis=1,inplace=True)

df = df.replace({"NO":0,
                    "<30":1,
                    ">30":0})

df = df.drop(df.loc[df["gender"]=="Unknown/Invalid"].index, axis=0)

df.age = df.age.replace({"[70-80)":75,
                         "[60-70)":65,
                         "[50-60)":55,
                         "[80-90)":85,
                         "[40-50)":45,
                         "[30-40)":35,
                         "[90-100)":95,
                         "[20-30)":25,
                         "[10-20)":15,
                         "[0-10)":5})

mapped = {1.0:"Emergency",
          2.0:"Emergency",
          3.0:"Elective",
          4.0:"New Born",
          5.0:np.nan,
          6.0:np.nan,
          7.0:"Trauma Center",
          8.0:np.nan}

df.admission_type_id = df.admission_type_id.replace(mapped)

mapped_discharge = {1:"Discharged to Home",
                    6:"Discharged to Home",
                    8:"Discharged to Home",
                    13:"Discharged to Home",
                    19:"Discharged to Home",
                    18:np.nan,25:np.nan,26:np.nan,
                    2:"Other",3:"Other",4:"Other",
                    5:"Other",7:"Other",9:"Other",
                    10:"Other",11:"Other",12:"Other",
                    14:"Other",15:"Other",16:"Other",
                    17:"Other",20:"Other",21:"Other",
                    22:"Other",23:"Other",24:"Other",
                    27:"Other",28:"Other",29:"Other",30:"Other"}

df["discharge_disposition_id"] = df["discharge_disposition_id"].replace(mapped_discharge)

mapped_adm = {1:"Referral",2:"Referral",3:"Referral",
              4:"Other",5:"Other",6:"Other",10:"Other",22:"Other",25:"Other",
              9:"Other",8:"Other",14:"Other",13:"Other",11:"Other",
              15:np.nan,17:np.nan,20:np.nan,21:np.nan,
              7:"Emergency"}
df.admission_source_id = df.admission_source_id.replace(mapped_adm)

df['race'] = df['race'].fillna(df['race'].mode()[0])
df['admission_type_id'] = df['admission_type_id'].fillna(df['admission_type_id'].mode()[0])
df['discharge_disposition_id'] = df['discharge_disposition_id'].fillna(df['discharge_disposition_id'].mode()[0])
df['admission_source_id'] = df['admission_source_id'].fillna(df['admission_source_id'].mode()[0])
df.drop(['encounter_id','patient_nbr'],axis=1,inplace=True)

print(df[df['readmitted']==1].shape)
print(df[df['readmitted']==0].shape)

X = df.drop('readmitted',axis=1)
y = df['readmitted']

# Separa las variables categóricas y numéricas
categorical_features = df.select_dtypes('O')
numeric_features = df.select_dtypes(np.number)

# create an operation to get dummy varibles of categorical variables
class GetDummyVariable(BaseEstimator, TransformerMixin):
    def __init__(self, categorical_features=None, drop_first=False):
        self.categorical_features = categorical_features
        self.drop_first = drop_first

    def replace_illegal_name(self, X_train_dummies):
        # replace '[', ']' and '<' because they are invalud as column names in xgboost
        # replace '[' with '('; '<' with 'less than'; '>' with 'greater than'
        for s in X_train_dummies.columns:
            new_name = re.sub(r'\[', '(', s)
            X_train_dummies.rename(columns={s:new_name},inplace=True)

        for s in X_train_dummies.columns:
            new_name = re.sub(r'\<', 'less_than', s)
            X_train_dummies.rename(columns={s:new_name},inplace=True)

        for s in X_train_dummies.columns:
            new_name = re.sub(r'\>', 'greater_than', s)
            X_train_dummies.rename(columns={s:new_name},inplace=True)
        return X_train_dummies

    def fit(self, X, y):
        # get categorical features
        self.categorical_features = [col for col in X.columns if X[col].dtype.name in ('category', 'object')]
        return self

    def transform(self, X):
        # get dummy variables
        X_dummies = pd.get_dummies(X, columns=self.categorical_features,drop_first=self.drop_first)
        return self.replace_illegal_name(X_dummies)

class MyStandardScaler(BaseEstimator, TransformerMixin):
    def __init__(self, scaler):
        self.scaler = scaler

    def fit(self, X, y):
        self.scaler.fit(X)
        return self

    def transform(self, X):
        new_X = self.scaler.transform(X)
        return pd.DataFrame(new_X, columns=X.columns)

# Define el modelo final del pipeline
model = RandomForestClassifier()

preprocessor = Pipeline([
    ('encoder', GetDummyVariable()),
    ('scaler', MyStandardScaler(StandardScaler())),
    ('classifier', model)
])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# reset index, make it starts from 0
X_train.reset_index(drop=True,inplace=True)
y_train.reset_index(drop=True,inplace=True)

print(X_train.shape)

X_test.reset_index(drop=True,inplace=True)
y_test.reset_index(drop=True,inplace=True)

preprocessor.fit(X_train, y_train)

y_pred = preprocessor.predict(X_test)

print(confusion_matrix(y_test,y_pred))

print(accuracy_score(y_test,y_pred))

print(recall_score(y_test,y_pred))
